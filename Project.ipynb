{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xml.etree import ElementTree\n",
    "import re\n",
    "from StringIO import StringIO\n",
    "from bs4 import BeautifulSoup\n",
    "import os \n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'bahia cocoa review', u'standard oil  to form financial unit', u'texas commerce bancshares  files plan', u'talking point/bankamerica  equity offer', u'national average prices for farmerowned reserve', u'argentine 1986/87 grain/oilseed registrations', u'red lion inns files plans offering', u'usx  debt dowgraded by moodys', u'champion products  approves stock split', u'computer terminal systems  completes sale', u'cobanco inc  year net', u'ohio mattress  may have lower 1st qtr net', u'am international inc  2nd qtr jan 31', u'brownforman inc  4th qtr net', u'national intergroup to offer permian units', u'economic spotlight  bankamerica ', u'national health enhancement  new program', u'dean foods  sees strong 4th qtr earnings', u'bonus wheat flour for north yemen   usda', u'credit card disclosure bills introduced', u'hughes capital unit signs pact with bear stearns', u'magma lowers copper 075 cent to 66 cts', u'brownforman  sets stock split ups payout', u'esquire radio and electronics inc  4th qtr', u'shearson lehman names new managing director']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "totstring=\"\"\n",
    "\n",
    "with open(\"Data/reut2-000.sgm\",'r') as inF:\n",
    "    for line in inF:\n",
    "        string2=re.sub(\"&.*?>\",\"\",line,flags=re.UNICODE)\n",
    "        string=re.sub(\"[^0-9a-zA-Z<>/\\s=!-\\\"\\\"]+\",\"\",string2.lower())\n",
    "        totstring+=string\n",
    "    \n",
    "soup= BeautifulSoup(totstring)\n",
    "\n",
    "items_date=list()\n",
    "items_places=list()\n",
    "items_title=list()\n",
    "items_body=list()\n",
    "\n",
    "\n",
    "\n",
    "for a in soup.findAll(\"content\"):\n",
    "    items_body.append(a.getText())\n",
    "\n",
    "for b in soup.findAll(\"title\"):\n",
    "    items_title.append(b.getText())\n",
    "\n",
    "for c in soup.findAll(\"places\"):\n",
    "    items_places.append(c.getText())\n",
    "\n",
    "for d in soup.findAll(\"date\"):\n",
    "    items_date.append(d.getText())\n",
    "    \n",
    "\n",
    "corpus = items_title[0:25]\n",
    "print(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'copper': 1, u'radio': 1, u'signs': 1, u'mattress': 1, u'jan': 1, u'to': 3, u'program': 1, u'systems': 1, u'equity': 1, u'texas': 1, u'split': 2, u'flour': 1, u'bear': 1, u'new': 2, u'electronics': 1, u'farmerowned': 1, u'qtr': 5, u'registrations': 1, u'ohio': 1, u'bills': 1, u'ups': 1, u'bahia': 1, u'financial': 1, u'national': 3, u'lion': 1, u'computer': 1, u'enhancement': 1, u'year': 1, u'plans': 1, u'and': 1, u'for': 2, u'lehman': 1, u'managing': 1, u'review': 1, u'may': 1, u'health': 1, u'capital': 1, u'international': 1, u'net': 3, u'red': 1, u'wheat': 1, u'standard': 1, u'bancshares': 1, u'strong': 1, u'by': 1, u'card': 1, u'payout': 1, u'stearns': 1, u'cts': 1, u'31': 1, u'credit': 1, u'products': 1, u'introduced': 1, u'lowers': 1, u'disclosure': 1, u'usda': 1, u'2nd': 1, u'cocoa': 1, u'names': 1, u'66': 1, u'1st': 1, u'inns': 1, u'unit': 2, u'terminal': 1, u'debt': 1, u'cent': 1, u'usx': 1, u'files': 2, u'bankamerica': 1, u'north': 1, u'champion': 1, u'offering': 1, u'offer': 2, u'point/bankamerica': 1, u'prices': 1, u'with': 1, u'completes': 1, u'pact': 1, u'commerce': 1, u'hughes': 1, u'1986/87': 1, u'brownforman': 2, u'magma': 1, u'economic': 1, u'argentine': 1, u'yemen': 1, u'spotlight': 1, u'dowgraded': 1, u'075': 1, u'sees': 1, u'am': 1, u'talking': 1, u'foods': 1, u'have': 1, u'shearson': 1, u'inc': 4, u'form': 1, u'grain/oilseed': 1, u'dean': 1, u'earnings': 1, u'esquire': 1, u'units': 1, u'stock': 2, u'oil': 1, u'permian': 1, u'bonus': 1, u'approves': 1, u'director': 1, u'4th': 3, u'cobanco': 1, u'plan': 1, u'lower': 1, u'intergroup': 1, u'average': 1, u'sale': 1, u'sets': 1, u'moodys': 1, u'reserve': 1}\n"
     ]
    }
   ],
   "source": [
    "tf = {}\n",
    "for doc in corpus:\n",
    "    for word in doc.split():\n",
    "        # << COMPUTE ERM FREQUENCY DICTIONARY >> CODE HERE\n",
    "        ## HIDE\n",
    "        if word in tf:\n",
    "            tf[word] += 1\n",
    "        else:\n",
    "            tf[word] = 1\n",
    "        ## HIDE\n",
    "\n",
    "print(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({u'qtr': 5, u'inc': 4, u'to': 3, u'national': 3, u'net': 3, u'4th': 3, u'split': 2, u'new': 2, u'for': 2, u'unit': 2, u'files': 2, u'offer': 2, u'brownforman': 2, u'stock': 2, u'copper': 1, u'radio': 1, u'signs': 1, u'mattress': 1, u'jan': 1, u'program': 1, u'systems': 1, u'equity': 1, u'texas': 1, u'flour': 1, u'bear': 1, u'electronics': 1, u'farmerowned': 1, u'registrations': 1, u'ohio': 1, u'bills': 1, u'ups': 1, u'bahia': 1, u'financial': 1, u'lion': 1, u'computer': 1, u'enhancement': 1, u'year': 1, u'plans': 1, u'and': 1, u'lehman': 1, u'managing': 1, u'review': 1, u'may': 1, u'health': 1, u'capital': 1, u'international': 1, u'red': 1, u'wheat': 1, u'standard': 1, u'bancshares': 1, u'strong': 1, u'by': 1, u'card': 1, u'payout': 1, u'stearns': 1, u'cts': 1, u'31': 1, u'credit': 1, u'products': 1, u'introduced': 1, u'lowers': 1, u'disclosure': 1, u'usda': 1, u'2nd': 1, u'cocoa': 1, u'names': 1, u'66': 1, u'1st': 1, u'inns': 1, u'terminal': 1, u'debt': 1, u'cent': 1, u'usx': 1, u'bankamerica': 1, u'north': 1, u'champion': 1, u'offering': 1, u'point/bankamerica': 1, u'prices': 1, u'with': 1, u'completes': 1, u'pact': 1, u'commerce': 1, u'hughes': 1, u'1986/87': 1, u'magma': 1, u'economic': 1, u'argentine': 1, u'yemen': 1, u'spotlight': 1, u'dowgraded': 1, u'075': 1, u'sees': 1, u'am': 1, u'talking': 1, u'foods': 1, u'have': 1, u'shearson': 1, u'form': 1, u'grain/oilseed': 1, u'dean': 1, u'earnings': 1, u'esquire': 1, u'units': 1, u'oil': 1, u'permian': 1, u'bonus': 1, u'approves': 1, u'director': 1, u'cobanco': 1, u'plan': 1, u'lower': 1, u'intergroup': 1, u'average': 1, u'sale': 1, u'sets': 1, u'moodys': 1, u'reserve': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_tf(corpus):\n",
    "    tf = Counter()\n",
    "    for doc in corpus:\n",
    "        for word in doc.split():\n",
    "            # << CODE HERE\n",
    "            ## HIDE\n",
    "            tf[word] += 1\n",
    "    return tf\n",
    "\n",
    "tf = get_tf(corpus)\n",
    "print(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "10\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "tf = get_tf(items_title)\n",
    "#print(tf)\n",
    "print(tf['oil'])\n",
    "print(tf['national'])\n",
    "print(tf['japan'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'basra': 1, u'claims': 1, u'iran': 1, u'near': 1, u'new': 1, u'victories': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_tfd(corpus):\n",
    "    tfd = {}\n",
    "    for i,doc in enumerate(corpus):\n",
    "        tfd[i]={}\n",
    "        for word in doc.split():\n",
    "            if word in tfd[i]:\n",
    "                tfd[i][word] += 1\n",
    "            else:\n",
    "                tfd[i][word] = 1\n",
    "    return tfd\n",
    "            \n",
    "    \n",
    "tfd = get_tfd(items_title)\n",
    "tfd[234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'12': 1,\n",
       " u'15': 1,\n",
       " u'169': 1,\n",
       " u'1986': 4,\n",
       " u'1987': 1,\n",
       " u'223000': 1,\n",
       " u'29': 1,\n",
       " u'290000': 1,\n",
       " u'390000': 1,\n",
       " u'44': 1,\n",
       " u'5': 1,\n",
       " u'8': 1,\n",
       " u'a': 1,\n",
       " u'agriculture': 1,\n",
       " u'and': 1,\n",
       " u'annual': 1,\n",
       " u'arabia': 1,\n",
       " u'are': 1,\n",
       " u'argentina': 1,\n",
       " u'around': 1,\n",
       " u'at': 3,\n",
       " u'australia': 1,\n",
       " u'be': 1,\n",
       " u'because': 1,\n",
       " u'built': 1,\n",
       " u'calendar': 1,\n",
       " u'canada': 1,\n",
       " u'drawdown': 1,\n",
       " u'drop': 1,\n",
       " u'embassys': 1,\n",
       " u'end': 2,\n",
       " u'end1985': 1,\n",
       " u'end1987': 1,\n",
       " u'expected': 2,\n",
       " u'fall': 1,\n",
       " u'forecast': 1,\n",
       " u'from': 2,\n",
       " u'imports': 1,\n",
       " u'in': 3,\n",
       " u'indonesias': 1,\n",
       " u'it': 3,\n",
       " u'main': 1,\n",
       " u'mln': 2,\n",
       " u'near': 1,\n",
       " u'of': 2,\n",
       " u'on': 1,\n",
       " u'pct': 5,\n",
       " u'report': 1,\n",
       " u'reuter': 1,\n",
       " u'said': 3,\n",
       " u'saudi': 1,\n",
       " u'stocks': 3,\n",
       " u'suppliers': 1,\n",
       " u'the': 6,\n",
       " u'there': 1,\n",
       " u'to': 2,\n",
       " u'tonnes': 3,\n",
       " u'up': 2,\n",
       " u'us': 2,\n",
       " u'was': 1,\n",
       " u'were': 2,\n",
       " u'wheat': 2,\n",
       " u'will': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfd = get_tfd(items_body)\n",
    "tfd[234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tfm(corpus):\n",
    "    \n",
    "    def get_lexicon(corpus):\n",
    "        lexicon = set()\n",
    "        # << COMPUTE SET OF TERMS IN CORPUS >> CODE HERE\n",
    "        ## HIDE\n",
    "        for doc in corpus:\n",
    "            lexicon.update([word for word in doc.split()])\n",
    "        return list(lexicon)\n",
    "        ## HIDE\n",
    "        \n",
    "    lexicon = get_lexicon(corpus)\n",
    "\n",
    "    tfm =[]\n",
    "    for doc in corpus:\n",
    "        tfv = [0]*len(lexicon)\n",
    "        for term in doc.split():\n",
    "            # << COMPUTE DOCUMENT TERM FREQUENCY VECTOR AND APPEND TO tfm >> CODE HERE\n",
    "            ## HIDE\n",
    "            tfv[lexicon.index(term)] += 1\n",
    "            ## HIDE\n",
    "        tfm.append(tfv)\n",
    "        \n",
    "    return tfm, lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 from recall set of 984 items:\n",
      "\t1.00 - nippon light metal continues aluminium output cut\n",
      "\t0.00 - bahia cocoa review\n",
      "\t0.00 - standard oil  to form financial unit\n",
      "\t0.00 - texas commerce bancshares  files plan\n",
      "\t0.00 - talking point/bankamerica  equity offer\n",
      "\t0.00 - national average prices for farmerowned reserve\n",
      "\t0.00 - argentine 1986/87 grain/oilseed registrations\n",
      "\t0.00 - red lion inns files plans offering\n",
      "\t0.00 - usx  debt dowgraded by moodys\n",
      "\t0.00 - champion products  approves stock split\n"
     ]
    }
   ],
   "source": [
    "def get_results_tf(qry, tfm, lexicon):\n",
    "    qrv = [0]*len(lexicon)\n",
    "    for term in qry.split():\n",
    "        if term in lexicon:\n",
    "            qrv[lexicon.index(term)] = 1\n",
    "\n",
    "    results = []      \n",
    "    for i, tfv in enumerate(tfm):\n",
    "        score = 0\n",
    "\n",
    "        score = sum([ xy[0] * xy[1] for xy in zip(qrv,tfv)])\n",
    "\n",
    "        results.append([score, i])\n",
    "    \n",
    "    sorted_results = sorted(results, key=lambda t: t[0] * -1 )\n",
    "    return sorted_results\n",
    "\n",
    "\n",
    "def print_results(results,n, head=True):\n",
    "    ''' Helper function to print results\n",
    "    '''\n",
    "    if head:    \n",
    "        print('\\nTop %d from recall set of %d items:' % (n,len(results)))\n",
    "        for r in results[:n]:\n",
    "            print('\\t%0.2f - %s'%(r[0],items_title[r[1]]))\n",
    "    else:\n",
    "        print('\\nBottom %d from recall set of %d items:' % (n,len(results)))\n",
    "        for r in results[-n:]:\n",
    "            print('\\t%0.2f - %s'%(r[0],items_title[r[1]]))\n",
    "    \n",
    "\n",
    "tfm, lexicon = get_tfm(items_title)\n",
    "results = get_results_tf('led bike light', tfm , lexicon)\n",
    "print_results(results,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arvin inds  promotes evans to president\n"
     ]
    }
   ],
   "source": [
    "def create_inverted_index(corpus):\n",
    "    idx={}\n",
    "    for i, doc in enumerate(corpus):\n",
    "        for word in doc.split():\n",
    "            if word in idx:\n",
    "                idx[word].append(i)\n",
    "            else:\n",
    "                idx[word] = [i]\n",
    "    return idx\n",
    "\n",
    "idx = create_inverted_index(items_title)\n",
    "print(items_title[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 from recall set of 156 items:\n",
      "\t2.00 - texaco canada cuts crude prices 64 canadian cts/bbl par grade to 2226 canadian dlrs\n",
      "\n",
      "\t2.00 - share trading in cheung kong group suspended\n",
      "\t2.00 - sncf issuing three billion franc domestic bond\n",
      "\t2.00 - france has little room for manoeuvre oecd says\n",
      "\t2.00 - calny inc  sues pepsico inc \n",
      "\t2.00 - pemex signs 500 mln dlr japan loan for pipeline\n",
      "\t2.00 - turkish retail prices rise 27 pct in february\n",
      "\t1.00 - bahia cocoa review\n",
      "\t1.00 - talking point/bankamerica  equity offer\n",
      "\t1.00 - national average prices for farmerowned reserve\n"
     ]
    }
   ],
   "source": [
    "def get_results_tf(qry, idx):\n",
    "    score = Counter()\n",
    "    for term in qry.split():\n",
    "        for doc in idx[term]:\n",
    "            score[doc] += 1\n",
    "            \n",
    "    results=[]\n",
    "    for x in [[r[0],r[1]] for r in zip(score.keys(), score.values())]:\n",
    "        if x[1] > 0:\n",
    "            results.append([x[1],x[0]])\n",
    "\n",
    "    sorted_results = sorted(results, key=lambda t: t[0] * -1 )\n",
    "    return sorted_results;\n",
    "\n",
    "\n",
    "idx = create_inverted_index(items_body)\n",
    "results = get_results_tf('national japan oil ', idx)\n",
    "print_results(results,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({319: 23.540833181893703, 916: 17.39024498911335, 827: 17.39024498911335, 846: 16.81488084420979, 850: 13.45190467536783, 317: 10.664292651429434, 823: 10.376610578977655, 885: 10.376610578977655, 328: 10.088928506525873, 205: 10.088928506525873, 189: 10.088928506525873, 857: 7.3013164825874775, 336: 7.3013164825874775, 835: 7.013634410135696, 403: 6.725952337683915, 219: 6.725952337683915, 683: 3.6506582412937387, 270: 3.6506582412937387, 661: 3.6506582412937387, 163: 3.6506582412937387, 293: 3.6506582412937387, 811: 3.6506582412937387, 826: 3.6506582412937387, 327: 3.6506582412937387, 216: 3.6506582412937387, 217: 3.6506582412937387, 95: 3.6506582412937387, 587: 3.6506582412937387, 707: 3.6506582412937387, 120: 3.6506582412937387, 249: 3.6506582412937387, 389: 3.3629761688419575, 262: 3.3629761688419575, 265: 3.3629761688419575, 16: 3.3629761688419575, 283: 3.3629761688419575, 422: 3.3629761688419575, 299: 3.3629761688419575, 687: 3.3629761688419575, 696: 3.3629761688419575, 316: 3.3629761688419575, 702: 3.3629761688419575, 201: 3.3629761688419575, 842: 3.3629761688419575, 203: 3.3629761688419575, 865: 3.3629761688419575, 830: 3.3629761688419575, 828: 3.3629761688419575})\n",
      "reuters to carry jiji financial services\n",
      "\n",
      "Top 10 from recall set of 48 items:\n",
      "\t23.54 - reuters to carry jiji financial services\n",
      "\t17.39 - italy consumer prices rise 04 pct in february\n",
      "\t17.39 - microbio  plans acquisition financing\n",
      "\t16.81 - dallas corp  4th qtr loss\n",
      "\t13.45 - calny inc  sues pepsico inc \n",
      "\t10.66 - sncf issuing three billion franc domestic bond\n",
      "\t10.38 - leucadia  has 72 pct of minstar \n",
      "\t10.38 - neutral budget expected in singapore\n",
      "\t10.09 - alaska housing has 150 mln dlr syndicated loan\n",
      "\t10.09 - japan consumer prices fall 04 pct in january\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def create_inverted_index(corpus):\n",
    "    idx={}\n",
    "    for i, doc in enumerate(corpus):\n",
    "        for word in doc.split():\n",
    "            if word in idx:\n",
    "                if i in idx[word]:\n",
    "                    idx[word][i] += 1\n",
    "                else:    \n",
    "                    idx[word][i] = 1\n",
    "            else:\n",
    "                idx[word] = {i:1}\n",
    "    return idx\n",
    "\n",
    "def get_results_tfidf(qry, idx, n):\n",
    "    score = Counter()\n",
    "    for term in qry.split():\n",
    "     \n",
    "        if term in idx:\n",
    "      \n",
    "            i = math.log(float(n)/(1+len(idx[term])))\n",
    "            for doc in idx[term]:\n",
    "                score[doc] += idx[term][doc] * i\n",
    "\n",
    "    results=[]\n",
    "    for x in [[r[0],r[1]] for r in zip(score.keys(), score.values())]:\n",
    "        if x[1] > 0:\n",
    "            results.append([x[1],x[0]])\n",
    "    \n",
    "    sorted_results = sorted(results, key=lambda t: t[0] * -1 )\n",
    "    type(score)\n",
    "    print(score)\n",
    "    return sorted_results\n",
    "\n",
    "idx_body = create_inverted_index(items_body)\n",
    "\n",
    "\n",
    "\n",
    "#results = get_results_tfidf('this is the end of the file', idx, len(items_body))\n",
    "#results = get_results_tfidf('japan the oil bankrupt this', idx, len(items_body))\n",
    "results = get_results_tfidf('The japan country', idx_body, len(items_body))\n",
    "#results = get_results_tfidf('japan oil bankrupt', idx, len(items_body))\n",
    "print(items_title[319])\n",
    "print_results(results,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 from recall set of 282 items:\n",
      "\t32.90 - coradian corp  4th qtr net\n",
      "\t23.85 - kuwait says no plans for emergency opec talks\n",
      "\t20.87 - oracle systems corp  to offer stock\n",
      "\t17.37 - pittston agrees to acquire wtc international in exchange of stock\n",
      "\n",
      "\t17.09 - cbt february volume down 14 pct from year ago\n",
      "\t16.34 - champion products  approves stock split\n",
      "\t15.81 - texas commerce bancshares  files plan\n",
      "\t15.81 - national intergroup to offer permian units\n",
      "\t15.81 - alcan aluminium ltd  sets stock split\n",
      "\t14.53 -  makes initial stock offer\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def create_inverted_index(corpus):\n",
    "    idx={}\n",
    "    for i, doc in enumerate(corpus):\n",
    "        for word in doc.split():\n",
    "            if word in idx:\n",
    "                if i in idx[word]:\n",
    "                    idx[word][i] += 1\n",
    "                else:    \n",
    "                    idx[word][i] = 1\n",
    "            else:\n",
    "                idx[word] = {i:1}\n",
    "    return idx\n",
    "\n",
    "def get_results_tfidf(qry, idx_body, n, idx_title, nn):\n",
    "    score = Counter()\n",
    "    score2 = Counter()\n",
    "    for term in qry.split():\n",
    "        if term in idx_body:\n",
    "            i = math.log(float(n)/(1+len(idx_body[term])))\n",
    "            for doc in idx_body[term]:\n",
    "                score[doc] += idx_body[term][doc] * i\n",
    "                \n",
    "        if term in idx_title:\n",
    "            #i = 5*math.log(float(n)/(1+len(idx_body[term])))\n",
    "            '''\n",
    "            tf = get_tf(items_title)\n",
    "            #print(tf)\n",
    "            print(tf['oil'])\n",
    "            '''\n",
    "            \n",
    "            i =\n",
    "            for doc in idx_title[term]:\n",
    "                score2[doc] += idx_title[term][doc]* i\n",
    "                \n",
    "    score = score + score2;\n",
    "\n",
    "    results=[]\n",
    "    for x in [[r[0],r[1]] for r in zip(score.keys(), score.values())]:\n",
    "        if x[1] > 0:\n",
    "            results.append([x[1],x[0]])\n",
    "    \n",
    "    sorted_results = sorted(results, key=lambda t: t[0] * -1 )\n",
    "    #type(score2)\n",
    "    #print(score2)\n",
    "    return sorted_results\n",
    "\n",
    "idx_body = create_inverted_index(items_body)\n",
    "idx_title= create_inverted_index(items_title)\n",
    "\n",
    "\n",
    "#results = get_results_tfidf('this is the end of the file', idx, len(items_body))\n",
    "#results = get_results_tfidf('japan the oil bankrupt this', idx, len(items_body))\n",
    "results = get_results_tfidf('stock market decline', idx_body, len(items_body),idx_title, len(items_title))\n",
    "#results = get_results_tfidf('japan oil bankrupt', idx, len(items_body))\n",
    "\n",
    "print_results(results,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'menu': 21, 'good': 16, 'happy': 10, 'bar': 8})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import Counter\n",
    "a = Counter({'menu': 20, 'good': 15, 'happy': 10, 'bar': 5})\n",
    "b = Counter({'good': 1, 'menu': 1, 'bar': 3})\n",
    "a=a + b\n",
    "#Counter({'menu': 21, 'good': 16, 'happy': 10, 'bar': 8})\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): findspark in /home/ubuntu/anaconda2/lib/python2.7/site-packages\r\n"
     ]
    }
   ],
   "source": [
    "! pip install findspark\n",
    "#START OF SPARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.context.SparkContext object at 0x7f84d07d1c10>\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "import os\n",
    "findspark.init('/home/ubuntu/workspace/spark-1.6.0-bin-hadoop2.6')\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-csv_2.10:1.3.0 pyspark-shell'\n",
    "\n",
    "from operator import add, mul \n",
    "\n",
    "import pyspark\n",
    "try: \n",
    "    print(sc)\n",
    "except NameError:\n",
    "    sc = pyspark.SparkContext()\n",
    "    print(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:-2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'bahia cocoa review',\n",
       " u'standard oil  to form financial unit',\n",
       " u'texas commerce bancshares  files plan',\n",
       " u'talking point/bankamerica  equity offer',\n",
       " u'national average prices for farmerowned reserve',\n",
       " u'argentine 1986/87 grain/oilseed registrations',\n",
       " u'red lion inns files plans offering',\n",
       " u'usx  debt dowgraded by moodys',\n",
       " u'champion products  approves stock split',\n",
       " u'computer terminal systems  completes sale']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#store clean data\n",
    "with open(\"Data/reuters_titles.txt\", 'w') as f:\n",
    "    for a in items_title:\n",
    "        f.write(\"%s\\n\" % a)\n",
    "        \n",
    "with open(\"Data/reuters_content.txt\", 'w') as f:\n",
    "    for a in items_body:\n",
    "        f.write(\"%s\\n\" % a)\n",
    "        \n",
    "with open(\"Data/reuters_date.txt\", 'w') as f:\n",
    "    for a in items_date:\n",
    "        f.write(\"%s\\n\" % a)\n",
    "        \n",
    "with open(\"Data/reuters_places.txt\", 'w') as f:\n",
    "    for a in items_places:\n",
    "        f.write(\"%s\\n\" % a)\n",
    "#upload clean data - upload to what Uriiiiiii\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rdd = sc.textFile(os.getcwd()+'/Data/reuters_titles.txt')\n",
    "print(rdd)\n",
    "\n",
    "rdd.take(10)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "terms1 = rdd.flatMap(lambda s : s.split(' ')) \\\n",
    "            .countByValue()\n",
    "\n",
    "terms2 = rdd.flatMap(lambda s : s.split()) \\\n",
    "            .map(lambda w : (w, 1)) \\\n",
    "            .reduceByKey(lambda x,y : x+y) \\\n",
    "            .collectAsMap()\n",
    "\n",
    "print(terms1['japan'])\n",
    "print(terms2['oil'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
