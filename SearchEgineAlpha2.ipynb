{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title: Search Engine Alpha 2.0\n",
    "<p><b>Abstract:</b> Search engine build using Reuters data set</p>\n",
    "<p><b>Authors:</b> Uriel Antonio & Ernesto Louie Cortez</p>\n",
    "<p><b>Date:</b>    04/30/2016</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xml.etree import ElementTree\n",
    "import re\n",
    "from StringIO import StringIO\n",
    "from bs4 import BeautifulSoup\n",
    "import os \n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "<p><b>Abstract: </b>Reuters data is organized in a generalized markup format.  Using BeatifulSoup, articles are scraped for their Title, content, date and place acording to their respective markup tags</p>\n",
    "\n",
    "<p><b>Challenges: </b>1) We initially made the assumption that all articles would have a date, place, title, and body.  During alpha 1 stage, it was found that titles and content became mismatched approximately 30 articles in.  Conditional statements were created to insert placeholders when content was missing.  2) The cleaned data was also littered with mark up tags for special symbols that also needed to be cleaned.    </p>\n",
    "\n",
    "\n",
    "<p><b></b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "totstring=\"\"\n",
    "\n",
    "with open(\"Data/reut2-000.sgm\",'r') as inF:\n",
    "    for line in inF:\n",
    "        string2=re.sub(\"&.*?>\",\"\",line,flags=re.UNICODE)\n",
    "        string3=re.sub(\"\\n\",\" \",string2,flags=re.UNICODE)\n",
    "        string=re.sub(\"[^0-9a-zA-Z<>/\\s=!-\\\"\\\"]+\",\"\",string3.lower())\n",
    "        totstring+=string\n",
    "    \n",
    "soup= BeautifulSoup(totstring)\n",
    "\n",
    "items_date=list()\n",
    "items_places=list()\n",
    "items_title=list()\n",
    "items_body=list()\n",
    "\n",
    "\n",
    "for a in soup.findAll(\"reuters\"):\n",
    "    if a.date != None:\n",
    "        items_date.append(a.date.getText())\n",
    "    else:\n",
    "        items_date.append(\"N/D\")\n",
    "    if a.places != None:\n",
    "        items_places.append(a.places.getText()) \n",
    "    else:\n",
    "        items_places.append(\"N/L\")\n",
    "    if a.title != None:\n",
    "        items_title.append(a.title.getText())  \n",
    "    else:\n",
    "        items_title.append(\"Untitled\")\n",
    "    if a.content != None:\n",
    "        items_body.append(a.content.getText())\n",
    "    else:\n",
    "        items_body.append(\"No Content.\")\n",
    "  \n",
    "\n",
    "corpus = items_title[0:25]\n",
    "print(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "tf = {}\n",
    "for doc in corpus:\n",
    "    for word in doc.split():\n",
    "        # << COMPUTE ERM FREQUENCY DICTIONARY >> CODE HERE\n",
    "        ## HIDE\n",
    "        if word in tf:\n",
    "            tf[word] += 1\n",
    "        else:\n",
    "            tf[word] = 1\n",
    "        ## HIDE\n",
    "\n",
    "print(tf)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_tf(corpus):\n",
    "    tf = Counter()\n",
    "    for doc in corpus:\n",
    "        for word in doc.split():\n",
    "            # << CODE HERE\n",
    "            ## HIDE\n",
    "            tf[word] += 1\n",
    "    return tf\n",
    "\n",
    "tf = get_tf(corpus)\n",
    "print(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf = get_tf(items_title)\n",
    "#print(tf)\n",
    "print(tf['oil'])\n",
    "print(tf['national'])\n",
    "print(tf['japan'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_tfd(corpus):\n",
    "    tfd = {}\n",
    "    for i,doc in enumerate(corpus):\n",
    "        tfd[i]={}\n",
    "        for word in doc.split():\n",
    "            if word in tfd[i]:\n",
    "                tfd[i][word] += 1\n",
    "            else:\n",
    "                tfd[i][word] = 1\n",
    "    return tfd\n",
    "            \n",
    "    \n",
    "tfd = get_tfd(items_title)\n",
    "tfd[234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfd = get_tfd(items_body)\n",
    "tfd[234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tfm(corpus):\n",
    "    \n",
    "    def get_lexicon(corpus):\n",
    "        lexicon = set()\n",
    "        # << COMPUTE SET OF TERMS IN CORPUS >> CODE HERE\n",
    "        ## HIDE\n",
    "        for doc in corpus:\n",
    "            lexicon.update([word for word in doc.split()])\n",
    "        return list(lexicon)\n",
    "        ## HIDE\n",
    "        \n",
    "    lexicon = get_lexicon(corpus)\n",
    "\n",
    "    tfm =[]\n",
    "    for doc in corpus:\n",
    "        tfv = [0]*len(lexicon)\n",
    "        for term in doc.split():\n",
    "            # << COMPUTE DOCUMENT TERM FREQUENCY VECTOR AND APPEND TO tfm >> CODE HERE\n",
    "            ## HIDE\n",
    "            tfv[lexicon.index(term)] += 1\n",
    "            ## HIDE\n",
    "        tfm.append(tfv)\n",
    "        \n",
    "    return tfm, lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_results_tf(qry, tfm, lexicon):\n",
    "    qrv = [0]*len(lexicon)\n",
    "    for term in qry.split():\n",
    "        if term in lexicon:\n",
    "            qrv[lexicon.index(term)] = 1\n",
    "\n",
    "    results = []      \n",
    "    for i, tfv in enumerate(tfm):\n",
    "        score = 0\n",
    "\n",
    "        score = sum([ xy[0] * xy[1] for xy in zip(qrv,tfv)])\n",
    "\n",
    "        results.append([score, i])\n",
    "    \n",
    "    sorted_results = sorted(results, key=lambda t: t[0] * -1 )\n",
    "    return sorted_results\n",
    "\n",
    "\n",
    "def print_results(results,n, head=True):\n",
    "    ''' Helper function to print results\n",
    "    '''\n",
    "    if head:    \n",
    "        print('\\nTop %d from recall set of %d items:' % (n,len(results)))\n",
    "        for r in results[:n]:\n",
    "            print('\\t%0.2f - %s'%(r[0],items_title[r[1]]))\n",
    "    else:\n",
    "        print('\\nBottom %d from recall set of %d items:' % (n,len(results)))\n",
    "        for r in results[-n:]:\n",
    "            print('\\t%0.2f - %s'%(r[0],items_title[r[1]]))\n",
    "    \n",
    "\n",
    "tfm, lexicon = get_tfm(items_title)\n",
    "results = get_results_tf('led bike light', tfm , lexicon)\n",
    "print_results(results,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_inverted_index(corpus):\n",
    "    idx={}\n",
    "    for i, doc in enumerate(corpus):\n",
    "        for word in doc.split():\n",
    "            if word in idx:\n",
    "                idx[word].append(i)\n",
    "            else:\n",
    "                idx[word] = [i]\n",
    "    return idx\n",
    "\n",
    "idx = create_inverted_index(items_title)\n",
    "print(items_title[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_results_tf(qry, idx):\n",
    "    score = Counter()\n",
    "    for term in qry.split():\n",
    "        for doc in idx[term]:\n",
    "            score[doc] += 1\n",
    "            \n",
    "    results=[]\n",
    "    for x in [[r[0],r[1]] for r in zip(score.keys(), score.values())]:\n",
    "        if x[1] > 0:\n",
    "            results.append([x[1],x[0]])\n",
    "\n",
    "    sorted_results = sorted(results, key=lambda t: t[0] * -1 )\n",
    "    return sorted_results;\n",
    "\n",
    "\n",
    "idx = create_inverted_index(items_body)\n",
    "results = get_results_tf('national japan oil ', idx)\n",
    "print_results(results,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def create_inverted_index(corpus):\n",
    "    idx={}\n",
    "    for i, doc in enumerate(corpus):\n",
    "        for word in doc.split():\n",
    "            if word in idx:\n",
    "                if i in idx[word]:\n",
    "                    idx[word][i] += 1\n",
    "                else:    \n",
    "                    idx[word][i] = 1\n",
    "            else:\n",
    "                idx[word] = {i:1}\n",
    "    return idx\n",
    "\n",
    "def get_results_tfidf(qry, idx, n):\n",
    "    score = Counter()\n",
    "    for term in qry.split():\n",
    "     \n",
    "        if term in idx:\n",
    "      \n",
    "            i = math.log(float(n)/(1+len(idx[term])))\n",
    "            for doc in idx[term]:\n",
    "                score[doc] += idx[term][doc] * i\n",
    "\n",
    "    results=[]\n",
    "    for x in [[r[0],r[1]] for r in zip(score.keys(), score.values())]:\n",
    "        if x[1] > 0:\n",
    "            results.append([x[1],x[0]])\n",
    "    \n",
    "    sorted_results = sorted(results, key=lambda t: t[0] * -1 )\n",
    "    type(score)\n",
    "    print(score)\n",
    "    return sorted_results\n",
    "\n",
    "idx_body = create_inverted_index(items_body)\n",
    "\n",
    "\n",
    "\n",
    "#results = get_results_tfidf('this is the end of the file', idx, len(items_body))\n",
    "#results = get_results_tfidf('japan the oil bankrupt this', idx, len(items_body))\n",
    "results = get_results_tfidf('The japan country', idx_body, len(items_body))\n",
    "#results = get_results_tfidf('japan oil bankrupt', idx, len(items_body))\n",
    "print(items_title[319])\n",
    "print_results(results,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
